{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"https://conductor.arcee.ai/v1\"\n",
    "model = \"auto\"\n",
    "\n",
    "api_key=os.getenv(\"CONDUCTOR_API_KEY\")   # You can sign up at https://conductor.arcee.ai\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_file = \"metadata-enrichment-test-data.jsonl\"\n",
    "column_name = \"Item\"\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        for item in reader:\n",
    "            data.append(item)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "lines = load_jsonl(input_data_file)\n",
    "\n",
    "# Display the first few items to verify the data loaded correctly\n",
    "print(f\"Loaded {len(lines)} items\")\n",
    "print(\"\\nSample items:\")\n",
    "for item in lines[:3]:\n",
    "    print(f\"Item: {item['Item']}\")\n",
    "    print(f\"SKU: {item['SKU']}\")\n",
    "    print(f\"Stock: {item['Stock']}\")\n",
    "    print(f\"Last Update: {item['LastUpdate']}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_item(item_data):\n",
    "    \"\"\"Process a single item with the model and return enriched data.\"\"\"\n",
    "    item_name = item_data[\"Item\"]\n",
    "    sku = item_data[\"SKU\"]\n",
    "    stock = item_data[\"Stock\"]\n",
    "    last_update = item_data[\"LastUpdate\"]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a medical equipment expert. Provide accurate descriptions, applications, and risks for medical items. Always respond with valid JSON.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                Based on the item \"{item_name}\", provide a valid JSON document with the following structure:\n",
    "                {{\n",
    "                  \"Description\": \"a human-readable description, in 1-2 sentences\",\n",
    "                  \"Applications\": [\"main use case 1\", \"main use case 2\", \"etc\"],\n",
    "                  \"Risks\": [\"main precaution 1\", \"main precaution 2\", \"etc\"]\n",
    "                }}\n",
    "                Your answer must stay within the medical equipment domain.\n",
    "                Don't reuse the item name in the description, applications or risks.\n",
    "                Ensure your response is a properly formatted JSON object with no additional text.\n",
    "                Make sure to add a closing brace at the end of the JSON object.\n",
    "                Don't add extra tabs or spaces.\n",
    "                Don't use Markdown or backticks.\n",
    "                \"\"\"\n",
    "            }\n",
    "        ],\n",
    "        stream=False,\n",
    "    )\n",
    "    \n",
    "    # Handle potential JSON parsing errors\n",
    "    try:\n",
    "        enriched_data = json.loads(response.choices[0].message.content)\n",
    "    except json.JSONDecodeError:\n",
    "        # Provide a fallback if the response isn't valid JSON\n",
    "        print(f\"\\nError parsing JSON for item: {item_name}\")\n",
    "        print(response.choices[0].message.content)\n",
    "        enriched_data = {\n",
    "            \"Description\": \"Description unavailable due to formatting error\",\n",
    "            \"Applications\": [\"Not available\"],\n",
    "            \"Risks\": [\"Not available\"]\n",
    "        }\n",
    "\n",
    "    # Print a dot to indicate progress\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Extract the model id, the number of input and output tokens from the response\n",
    "    model_id = response.model\n",
    "    input_tokens = response.usage.prompt_tokens\n",
    "    output_tokens = response.usage.completion_tokens\n",
    "    \n",
    "    merged_data = {\n",
    "        \"Item\": item_name,\n",
    "        \"SKU\": sku,\n",
    "        \"Stock\": stock,\n",
    "        \"LastUpdate\": last_update,\n",
    "        \"Description\": enriched_data.get(\"Description\", \"\"),\n",
    "        \"Applications\": enriched_data.get(\"Applications\", \"\"),\n",
    "        \"Risks\": enriched_data.get(\"Risks\", \"\"),\n",
    "    }\n",
    "    return {\n",
    "        \"merged_data\": merged_data,\n",
    "        \"accounting\": {\n",
    "            \"model_id\": model_id,\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "        }\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_lines = []\n",
    "accounting_data = []\n",
    "\n",
    "for line in lines:\n",
    "    result = process_item(line)\n",
    "    enriched_lines.append(result[\"merged_data\"])\n",
    "    accounting_data.append(result[\"accounting\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with model prices\n",
    "model_prices = {\n",
    "    \"claude-3-7-sonnet\": {\n",
    "        \"input_price_dollars\": 3.00,\n",
    "        \"output_price_dollars\": 15.00,\n",
    "    },\n",
    "    \"deepseek/r1\": {\n",
    "        \"input_price_dollars\": 3.00,\n",
    "        \"output_price_dollars\": 7.00,\n",
    "    },\n",
    "    \"gpt-4.1\": {\n",
    "        \"input_price_dollars\": 2.00,\n",
    "        \"output_price_dollars\": 8.00,\n",
    "    },\n",
    "    \"openai/o3-mini\": {\n",
    "        \"input_price_dollars\": 1.10,\n",
    "        \"output_price_dollars\": 4.40,\n",
    "    },\n",
    "    \"arcee-ai/virtuoso-large\": {\n",
    "        \"input_price_dollars\": 0.75,\n",
    "        \"output_price_dollars\": 1.20,\n",
    "    },\n",
    "    \"arcee-ai/virtuoso-medium-v2\": {\n",
    "        \"input_price_dollars\": 0.50,\n",
    "        \"output_price_dollars\": 0.80,\n",
    "    },\n",
    "    \"arcee-ai/arcee-blitz\": {\n",
    "        \"input_price_dollars\": 0.45,\n",
    "        \"output_price_dollars\": 0.75,\n",
    "    },\n",
    "    \"arcee-ai/caller-large\": {\n",
    "        \"input_price_dollars\": 0.55,\n",
    "        \"output_price_dollars\": 0.85,\n",
    "    },\n",
    "    \"arcee-ai/maestro-32b\": {\n",
    "        \"input_price_dollars\": 0.90,\n",
    "        \"output_price_dollars\": 3.30,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Reduce the accounting data on model_id\n",
    "# Calculate total tokens and cost by model\n",
    "model_summary = {}\n",
    "\n",
    "for entry in accounting_data:\n",
    "    model_id = entry['model_id']\n",
    "    if model_id.startswith(\"claude-3-7-sonnet\"):\n",
    "        model_id = \"claude-3-7-sonnet\"\n",
    "    if model_id.startswith(\"gpt-4.1\"):\n",
    "        model_id = \"gpt-4.1\"\n",
    "    input_tokens = entry['input_tokens']\n",
    "    output_tokens = entry['output_tokens']\n",
    "    \n",
    "    if model_id not in model_summary:\n",
    "        model_summary[model_id] = {\n",
    "            'total_input_tokens': 0,\n",
    "            'total_output_tokens': 0,\n",
    "            'total_tokens': 0,\n",
    "            'total_cost_dollars': 0,\n",
    "            'invocation_count': 0\n",
    "        }\n",
    "    \n",
    "    model_summary[model_id]['total_input_tokens'] += input_tokens\n",
    "    model_summary[model_id]['total_output_tokens'] += output_tokens\n",
    "    model_summary[model_id]['total_tokens'] += (input_tokens + output_tokens)\n",
    "    model_summary[model_id]['invocation_count'] += 1\n",
    "    \n",
    "    # Calculate cost if model exists in price dictionary\n",
    "    model_key = model_id.lower()  # Normalize for case-insensitive matching\n",
    "    \n",
    "    \n",
    "    for price_model in model_prices:\n",
    "        if price_model.lower() == model_key:\n",
    "            input_cost = input_tokens * model_prices[price_model]['input_price_dollars'] / 1e6\n",
    "            output_cost = output_tokens * model_prices[price_model]['output_price_dollars'] / 1e6\n",
    "            model_summary[model_id]['total_cost_dollars'] += (input_cost + output_cost)\n",
    "\n",
    "# Display the summary\n",
    "for model, stats in model_summary.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"  Invocation Count: {stats['invocation_count']}\")\n",
    "    print(f\"  Total Input Tokens: {stats['total_input_tokens']}\")\n",
    "    print(f\"  Total Output Tokens: {stats['total_output_tokens']}\")\n",
    "    print(f\"  Total Tokens: {stats['total_tokens']}\")\n",
    "    print(f\"  Total Cost: ${stats['total_cost_dollars']:.8f}\")\n",
    "    print()\n",
    "\n",
    "# Sum all the input and output tokens\n",
    "total_input_tokens = sum(stats['total_input_tokens'] for stats in model_summary.values())\n",
    "total_output_tokens = sum(stats['total_output_tokens'] for stats in model_summary.values())\n",
    "print(f\"Total Input Tokens: {total_input_tokens}\")\n",
    "print(f\"Total Output Tokens: {total_output_tokens}\")\n",
    "\n",
    "# Sum of all the costs\n",
    "total_cost = sum(stats['total_cost_dollars'] for stats in model_summary.values())\n",
    "print(f\"Total Cost: ${total_cost:.8f}\")\n",
    "print('')\n",
    "\n",
    "# Total cost if we had used claude-3-7-sonnet-20250219 for all the tokens\n",
    "claude_3_7_sonnet_cost = total_input_tokens * model_prices['claude-3-7-sonnet']['input_price_dollars'] + total_output_tokens * model_prices['claude-3-7-sonnet']['output_price_dollars']\n",
    "claude_3_7_sonnet_cost /= 1e6\n",
    "print(f\"Total Cost if we had used claude-3-7-sonnet: ${claude_3_7_sonnet_cost:.8f}\")\n",
    "print(f\"Cost Savings: {((total_cost - claude_3_7_sonnet_cost) / claude_3_7_sonnet_cost) * 100:.2f}%\")\n",
    "\n",
    "# Total cost if we had used gpt-4.1-2025-04-14 for all the tokens\n",
    "gpt_4_1_cost = total_input_tokens * model_prices['gpt-4.1']['input_price_dollars'] + total_output_tokens * model_prices['gpt-4.1']['output_price_dollars']\n",
    "gpt_4_1_cost /= 1e6\n",
    "print(f\"Total Cost if we had used gpt-4.1: ${gpt_4_1_cost:.8f}\")\n",
    "print(f\"Cost Savings: {((total_cost - gpt_4_1_cost) / gpt_4_1_cost) * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the enriched lines to a file\n",
    "enriched_lines_file = \"enriched_lines.jsonl\"\n",
    "\n",
    "with open(enriched_lines_file, \"w\") as f:\n",
    "    for line in enriched_lines:\n",
    "        f.write(json.dumps(line) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

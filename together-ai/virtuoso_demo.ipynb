{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Arcee AI Virtuoso Large Model Demo via Together.ai\n",
        "\n",
        "This notebook demonstrates how to use the [Arcee AI Virtuoso Large model](https://api.together.ai/models/arcee-ai/virtuoso-large) through the Together.ai API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U pip\n",
        "!pip install -qU together\n",
        "print(\"✅ Required packages installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Set Up API Key\n",
        "\n",
        "We'll use the API key stored in the environment variable `TOGETHER_API_KEY`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import together\n",
        "from IPython.display import Markdown, display, clear_output\n",
        "\n",
        "# Initialize the Together client\n",
        "api_key = os.environ.get(\"TOGETHER_API_KEY\")\n",
        "\n",
        "# Verify API key is available\n",
        "if api_key is None:\n",
        "    print(\"⚠️ TOGETHER_API_KEY environment variable not found. Please set it before proceeding.\")\n",
        "    print(\"You can set it with: import os; os.environ['TOGETHER_API_KEY'] = 'your_api_key_here'\")\n",
        "else:\n",
        "    # Create a client instance\n",
        "    client = together.Together(api_key=api_key)\n",
        "    print(\"✅ API key loaded successfully and client initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Basic Text Completion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_text(prompt, max_tokens=256):\n",
        "    \"\"\"Generate text using the Arcee AI Virtuoso Large model\"\"\"\n",
        "    try:            \n",
        "        response = client.completions.create(\n",
        "            prompt=prompt,\n",
        "            model=\"arcee-ai/virtuoso-large\",\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=0.7,\n",
        "        )\n",
        "        \n",
        "        # Access the response as an object, not a dictionary\n",
        "        return response.choices[0].text\n",
        "    except Exception as e:\n",
        "        return f\"Error generating text: {str(e)}\"\n",
        "\n",
        "# Example prompt\n",
        "prompt = \"Explain the concept of transfer learning in machine learning in simple terms:\"\n",
        "\n",
        "print(f\"Generating text for prompt: '{prompt}'\")\n",
        "response = generate_text(prompt)\n",
        "display(Markdown(f\"**Prompt:** {prompt}\\n\\n**Response:**\\n{response}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Chat Completion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat_completion(messages, max_tokens=256):\n",
        "    \"\"\"Generate a chat completion using the Arcee AI Virtuoso Large model\"\"\"\n",
        "    try:        \n",
        "        # Try to use the chat completions API first\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"arcee-ai/virtuoso-large\",\n",
        "                messages=messages,\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=0.7,\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            print(f\"Chat completions error: {e}\")\n",
        "            print(\"Falling back to completions API with manually formatted prompt...\")\n",
        "            \n",
        "            # Manually format the chat messages into a prompt as fallback\n",
        "            formatted_prompt = format_chat_prompt(messages)\n",
        "            \n",
        "            # Use the completions API\n",
        "            response = client.completions.create(\n",
        "                prompt=formatted_prompt,\n",
        "                model=\"arcee-ai/virtuoso-large\",\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=0.7,\n",
        "            )\n",
        "            \n",
        "            # Return the generated text\n",
        "            return response.choices[0].text\n",
        "    except Exception as e:\n",
        "        return f\"Error in chat completion: {str(e)}\"\n",
        "\n",
        "def format_chat_prompt(messages):\n",
        "    \"\"\"Manually format chat messages into a prompt string\"\"\"\n",
        "    prompt = \"\"\n",
        "    for message in messages:\n",
        "        role = message[\"role\"]\n",
        "        content = message[\"content\"]\n",
        "        \n",
        "        if role == \"system\":\n",
        "            prompt += f\"System: {content}\\n\\n\"\n",
        "        elif role == \"user\":\n",
        "            prompt += f\"User: {content}\\n\\n\"\n",
        "        elif role == \"assistant\":\n",
        "            prompt += f\"Assistant: {content}\\n\\n\"\n",
        "    \n",
        "    prompt += \"Assistant: \"\n",
        "    return prompt\n",
        "\n",
        "# Example chat\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant that provides concise and accurate information.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What are the key differences between supervised and unsupervised learning?\"}\n",
        "]\n",
        "\n",
        "print(\"Generating chat completion...\")\n",
        "response = chat_completion(messages)\n",
        "display(Markdown(f\"**System:** {messages[0]['content']}\\n\\n**User:** {messages[1]['content']}\\n\\n**Assistant:**\\n{response}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Streaming Response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stream_chat(messages, max_tokens=512):\n",
        "    \"\"\"Stream a chat completion using the Arcee AI Virtuoso Large model\"\"\"\n",
        "    response = \"\"\n",
        "    \n",
        "    try:\n",
        "        # Try to use the chat completions streaming API first\n",
        "        try:\n",
        "            print(\"Starting streaming response...\")\n",
        "            stream = client.chat.completions.create(\n",
        "                model=\"arcee-ai/virtuoso-large\",\n",
        "                messages=messages,\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=0.7,\n",
        "                stream=True,\n",
        "            )\n",
        "            \n",
        "            for chunk in stream:\n",
        "                if chunk.choices and chunk.choices[0].delta.content:\n",
        "                    text = chunk.choices[0].delta.content\n",
        "                    # Check for contaminated content\n",
        "                    if \"Human:\" in text or \"User:\" in text:\n",
        "                        print(\"⚠️ Detected contaminated content in response, truncating...\")\n",
        "                        break\n",
        "                    response += text\n",
        "                    clear_output(wait=True)\n",
        "                    display(Markdown(response))\n",
        "                    \n",
        "        except Exception as e:\n",
        "            print(f\"Chat completions streaming error: {e}\")\n",
        "            print(\"Falling back to non-streaming chat completion...\")\n",
        "            \n",
        "            # Use regular chat completion instead\n",
        "            response = chat_completion(messages, max_tokens=max_tokens)\n",
        "            clear_output(wait=True)\n",
        "            display(Markdown(response))\n",
        "            return response\n",
        "        \n",
        "        print(\"\\n\\nStreaming complete.\")\n",
        "        return response\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error in stream_chat: {str(e)}\")\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Example streaming chat\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant that provides concise and accurate information. Keep your responses focused on the question asked.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Explain the concept of gradient descent in machine learning in 3-4 paragraphs.\"}\n",
        "]\n",
        "\n",
        "print(\"Starting streaming chat...\")\n",
        "result = stream_chat(messages)\n",
        "print(\"\\nResponse length:\", len(result) if result else 0, \"characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Advanced Prompting with System Instructions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an expert data scientist who specializes in explaining complex concepts in simple terms. Format your responses using markdown with headers, bullet points, and code examples where appropriate.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Explain how to implement k-means clustering in Python and provide a simple example.\"}\n",
        "]\n",
        "\n",
        "print(\"Generating advanced response with system instructions...\")\n",
        "response = chat_completion(messages, max_tokens=512)\n",
        "print(\"Response received!\")\n",
        "display(Markdown(response))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Multi-turn Conversation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversation = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is a neural network?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"A neural network is a computational model inspired by the human brain. It consists of interconnected nodes (neurons) organized in layers that process information. Neural networks learn from data by adjusting the connections (weights) between neurons through a process called training. They're particularly effective for tasks like pattern recognition, classification, and prediction.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What are some common activation functions used in neural networks?\"}\n",
        "]\n",
        "\n",
        "print(\"Demonstrating multi-turn conversation...\")\n",
        "print(\"Previous context: Asked about neural networks\")\n",
        "print(\"Current question: Asking about activation functions\")\n",
        "response = chat_completion(conversation)\n",
        "display(Markdown(f\"**User:** {conversation[-1]['content']}\\n\\n**Assistant:**\\n{response}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Direct API Call (Fallback Method)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def direct_api_call(prompt, max_tokens=256):\n",
        "    \"\"\"Make a direct API call to Together.ai for the Arcee AI Virtuoso Large model\"\"\"\n",
        "    try:\n",
        "        api_key = os.environ.get('TOGETHER_API_KEY')\n",
        "        if api_key is None:\n",
        "            return \"API key not found. Please set TOGETHER_API_KEY environment variable.\"\n",
        "            \n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        \n",
        "        payload = {\n",
        "            \"model\": \"arcee-ai/virtuoso-large\",\n",
        "            \"prompt\": prompt,\n",
        "            \"max_tokens\": max_tokens,\n",
        "            \"temperature\": 0.7\n",
        "        }\n",
        "        \n",
        "        print(\"Making direct API call to Together.ai...\")\n",
        "        response = requests.post(\n",
        "            \"https://api.together.xyz/v1/completions\",\n",
        "            headers=headers,\n",
        "            json=payload\n",
        "        )\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            print(\"API call successful!\")\n",
        "            return result[\"choices\"][0][\"text\"]\n",
        "        else:\n",
        "            return f\"Error: {response.status_code} - {response.text}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error in direct API call: {str(e)}\"\n",
        "\n",
        "# Example direct API call\n",
        "direct_prompt = \"What is the difference between supervised and unsupervised learning?\"\n",
        "print(f\"Sending prompt: '{direct_prompt}'\")\n",
        "direct_response = direct_api_call(direct_prompt)\n",
        "display(Markdown(f\"**Prompt:** {direct_prompt}\\n\\n**Response:**\\n{direct_response}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated how to use the Arcee AI Virtuoso Large model through the Together.ai API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
